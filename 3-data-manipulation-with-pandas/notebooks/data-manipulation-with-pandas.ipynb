{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspecting a DataFrame\n",
    "When you get a new DataFrame to work with, the first thing you need to do is explore it and see what it contains. There are several useful methods and attributes for this.\n",
    "\n",
    "- head() returns the first few rows (the “head” of the DataFrame).\n",
    "- info() shows information on each of the columns, such as the data type and number of missing values.\n",
    "- shape returns the number of rows and columns of the DataFrame.\n",
    "- describe() calculates a few summary statistics for each column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               region       state  individuals  family_members  state_pop\n",
      "0  East South Central     Alabama       2570.0           864.0    4887681\n",
      "1             Pacific      Alaska       1434.0           582.0     735139\n",
      "2            Mountain     Arizona       7259.0          2606.0    7158024\n",
      "3  West South Central    Arkansas       2280.0           432.0    3009733\n",
      "4             Pacific  California     109008.0         20964.0   39461588\n"
     ]
    }
   ],
   "source": [
    "# Import pandas package\n",
    "import pandas as pd\n",
    "\n",
    "# Read homelessness data\n",
    "homelessness = pd.read_csv('../data/homelessness.csv')\n",
    "\n",
    "# Print the head of the homelessness data\n",
    "print(homelessness.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 51 entries, 0 to 50\n",
      "Data columns (total 5 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   region          51 non-null     object \n",
      " 1   state           51 non-null     object \n",
      " 2   individuals     51 non-null     float64\n",
      " 3   family_members  51 non-null     float64\n",
      " 4   state_pop       51 non-null     int64  \n",
      "dtypes: float64(2), int64(1), object(2)\n",
      "memory usage: 2.1+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Print information about homelessness\n",
    "print(homelessness.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(51, 5)\n"
     ]
    }
   ],
   "source": [
    "# Print the shape of homelessness\n",
    "print(homelessness.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         individuals  family_members     state_pop\n",
      "count      51.000000       51.000000  5.100000e+01\n",
      "mean     7225.784314     3504.882353  6.405637e+06\n",
      "std     15991.025083     7805.411811  7.327258e+06\n",
      "min       434.000000       75.000000  5.776010e+05\n",
      "25%      1446.500000      592.000000  1.777414e+06\n",
      "50%      3082.000000     1482.000000  4.461153e+06\n",
      "75%      6781.500000     3196.000000  7.340946e+06\n",
      "max    109008.000000    52070.000000  3.946159e+07\n"
     ]
    }
   ],
   "source": [
    "# Print a description of homelessness\n",
    "print(homelessness.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parts of a DataFrame\n",
    "To better understand DataFrame objects, it's useful to know that they consist of three components, stored as attributes:\n",
    "- values: A two-dimensional NumPy array of values.\n",
    "- columns: An index of columns: the column names.\n",
    "- index: An index for the rows: either row numbers or row names.\n",
    "\n",
    "You can usually think of indexes as a list of strings or numbers, though the pandas Index data type allows for more sophisticated options. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['East South Central' 'Alabama' 2570.0 864.0 4887681]\n",
      " ['Pacific' 'Alaska' 1434.0 582.0 735139]\n",
      " ['Mountain' 'Arizona' 7259.0 2606.0 7158024]\n",
      " ['West South Central' 'Arkansas' 2280.0 432.0 3009733]\n",
      " ['Pacific' 'California' 109008.0 20964.0 39461588]]\n"
     ]
    }
   ],
   "source": [
    "# Print the first 5 values of homelessness\n",
    "print(homelessness[:5].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['region', 'state', 'individuals', 'family_members', 'state_pop'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Print the column index of homelessness\n",
    "print(homelessness.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RangeIndex(start=0, stop=51, step=1)\n"
     ]
    }
   ],
   "source": [
    "# Print the row index of homelessness\n",
    "print(homelessness.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sorting rows\n",
    "Finding interesting bits of data in a DataFrame is often easier if you change the order of the rows. You can sort the rows by passing a column name to .sort_values().\n",
    "\n",
    "In cases where rows have the same value (this is common if you sort on a categorical variable), you may wish to break the ties by sorting on another column. You can sort on multiple columns in this way by passing a list of column names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>region</th>\n",
       "      <th>state</th>\n",
       "      <th>individuals</th>\n",
       "      <th>family_members</th>\n",
       "      <th>state_pop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>East South Central</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>2570.0</td>\n",
       "      <td>864.0</td>\n",
       "      <td>4887681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mountain</td>\n",
       "      <td>Arizona</td>\n",
       "      <td>7259.0</td>\n",
       "      <td>2606.0</td>\n",
       "      <td>7158024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Pacific</td>\n",
       "      <td>Alaska</td>\n",
       "      <td>1434.0</td>\n",
       "      <td>582.0</td>\n",
       "      <td>735139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pacific</td>\n",
       "      <td>California</td>\n",
       "      <td>109008.0</td>\n",
       "      <td>20964.0</td>\n",
       "      <td>39461588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>West South Central</td>\n",
       "      <td>Arkansas</td>\n",
       "      <td>2280.0</td>\n",
       "      <td>432.0</td>\n",
       "      <td>3009733</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               region       state  individuals  family_members  state_pop\n",
       "0  East South Central     Alabama       2570.0           864.0    4887681\n",
       "2            Mountain     Arizona       7259.0          2606.0    7158024\n",
       "1             Pacific      Alaska       1434.0           582.0     735139\n",
       "4             Pacific  California     109008.0         20964.0   39461588\n",
       "3  West South Central    Arkansas       2280.0           432.0    3009733"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select the first five rows then sort a one column:\n",
    "homelessness[:5].sort_values('region')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>region</th>\n",
       "      <th>state</th>\n",
       "      <th>individuals</th>\n",
       "      <th>family_members</th>\n",
       "      <th>state_pop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>West South Central</td>\n",
       "      <td>Arkansas</td>\n",
       "      <td>2280.0</td>\n",
       "      <td>432.0</td>\n",
       "      <td>3009733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>West South Central</td>\n",
       "      <td>Louisiana</td>\n",
       "      <td>2540.0</td>\n",
       "      <td>519.0</td>\n",
       "      <td>4659690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>West South Central</td>\n",
       "      <td>Oklahoma</td>\n",
       "      <td>2823.0</td>\n",
       "      <td>1048.0</td>\n",
       "      <td>3940235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>West South Central</td>\n",
       "      <td>Texas</td>\n",
       "      <td>19199.0</td>\n",
       "      <td>6111.0</td>\n",
       "      <td>28628666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>West North Central</td>\n",
       "      <td>North Dakota</td>\n",
       "      <td>467.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>758080</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                region         state  individuals  family_members  state_pop\n",
       "3   West South Central      Arkansas       2280.0           432.0    3009733\n",
       "18  West South Central     Louisiana       2540.0           519.0    4659690\n",
       "36  West South Central      Oklahoma       2823.0          1048.0    3940235\n",
       "43  West South Central         Texas      19199.0          6111.0   28628666\n",
       "34  West North Central  North Dakota        467.0            75.0     758080"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To sort multiple columns and descend the first column then print only the first five rows:\n",
    "homelessness.sort_values(['region', 'individuals'], ascending=[False, True])[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Subsetting rows\n",
    "A large part of data science is about finding which bits of your dataset are interesting. One of the simplest techniques for this is to find a subset of rows that match some criteria. This is sometimes known as filtering rows or selecting rows.\n",
    "\n",
    "There are many ways to subset a DataFrame, perhaps the most common is to use relational operators to return True or False for each row, then pass that inside square brackets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>region</th>\n",
       "      <th>state</th>\n",
       "      <th>individuals</th>\n",
       "      <th>family_members</th>\n",
       "      <th>state_pop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pacific</td>\n",
       "      <td>California</td>\n",
       "      <td>109008.0</td>\n",
       "      <td>20964.0</td>\n",
       "      <td>39461588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>South Atlantic</td>\n",
       "      <td>Florida</td>\n",
       "      <td>21443.0</td>\n",
       "      <td>9587.0</td>\n",
       "      <td>21244317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Mid-Atlantic</td>\n",
       "      <td>New York</td>\n",
       "      <td>39827.0</td>\n",
       "      <td>52070.0</td>\n",
       "      <td>19530351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Pacific</td>\n",
       "      <td>Oregon</td>\n",
       "      <td>11139.0</td>\n",
       "      <td>3337.0</td>\n",
       "      <td>4181886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>West South Central</td>\n",
       "      <td>Texas</td>\n",
       "      <td>19199.0</td>\n",
       "      <td>6111.0</td>\n",
       "      <td>28628666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Pacific</td>\n",
       "      <td>Washington</td>\n",
       "      <td>16424.0</td>\n",
       "      <td>5880.0</td>\n",
       "      <td>7523869</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                region       state  individuals  family_members  state_pop\n",
       "4              Pacific  California     109008.0         20964.0   39461588\n",
       "9       South Atlantic     Florida      21443.0          9587.0   21244317\n",
       "32        Mid-Atlantic    New York      39827.0         52070.0   19530351\n",
       "37             Pacific      Oregon      11139.0          3337.0    4181886\n",
       "43  West South Central       Texas      19199.0          6111.0   28628666\n",
       "47             Pacific  Washington      16424.0          5880.0    7523869"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter for rows where individuals is greater than 10000\n",
    "homelessness[homelessness['individuals'] > 1e4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>region</th>\n",
       "      <th>state</th>\n",
       "      <th>individuals</th>\n",
       "      <th>family_members</th>\n",
       "      <th>state_pop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mountain</td>\n",
       "      <td>Arizona</td>\n",
       "      <td>7259.0</td>\n",
       "      <td>2606.0</td>\n",
       "      <td>7158024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Mountain</td>\n",
       "      <td>Colorado</td>\n",
       "      <td>7607.0</td>\n",
       "      <td>3250.0</td>\n",
       "      <td>5691287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Mountain</td>\n",
       "      <td>Idaho</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>715.0</td>\n",
       "      <td>1750536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Mountain</td>\n",
       "      <td>Montana</td>\n",
       "      <td>983.0</td>\n",
       "      <td>422.0</td>\n",
       "      <td>1060665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Mountain</td>\n",
       "      <td>Nevada</td>\n",
       "      <td>7058.0</td>\n",
       "      <td>486.0</td>\n",
       "      <td>3027341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Mountain</td>\n",
       "      <td>New Mexico</td>\n",
       "      <td>1949.0</td>\n",
       "      <td>602.0</td>\n",
       "      <td>2092741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Mountain</td>\n",
       "      <td>Utah</td>\n",
       "      <td>1904.0</td>\n",
       "      <td>972.0</td>\n",
       "      <td>3153550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>Mountain</td>\n",
       "      <td>Wyoming</td>\n",
       "      <td>434.0</td>\n",
       "      <td>205.0</td>\n",
       "      <td>577601</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      region       state  individuals  family_members  state_pop\n",
       "2   Mountain     Arizona       7259.0          2606.0    7158024\n",
       "5   Mountain    Colorado       7607.0          3250.0    5691287\n",
       "12  Mountain       Idaho       1297.0           715.0    1750536\n",
       "26  Mountain     Montana        983.0           422.0    1060665\n",
       "28  Mountain      Nevada       7058.0           486.0    3027341\n",
       "31  Mountain  New Mexico       1949.0           602.0    2092741\n",
       "44  Mountain        Utah       1904.0           972.0    3153550\n",
       "50  Mountain     Wyoming        434.0           205.0     577601"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter for rows where region is Mountain\n",
    "homelessness[homelessness['region'] == 'Mountain']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>region</th>\n",
       "      <th>state</th>\n",
       "      <th>individuals</th>\n",
       "      <th>family_members</th>\n",
       "      <th>state_pop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Pacific</td>\n",
       "      <td>Alaska</td>\n",
       "      <td>1434.0</td>\n",
       "      <td>582.0</td>\n",
       "      <td>735139</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    region   state  individuals  family_members  state_pop\n",
       "1  Pacific  Alaska       1434.0           582.0     735139"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter for rows where family_members is less than 1000 and region is Pacific\n",
    "homelessness[(homelessness['family_members'] < 1000) & (homelessness['region'] == 'Pacific')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Subsetting rows by categorical variables\n",
    "Subsetting data based on a categorical variable often involves using the \"or\" operator (|) to select rows from multiple categories. This can get tedious when you want all states in one of three different regions, for example. Instead, use the .isin() method, which will allow you to tackle this problem by writing one condition instead of three separate ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>region</th>\n",
       "      <th>state</th>\n",
       "      <th>individuals</th>\n",
       "      <th>family_members</th>\n",
       "      <th>state_pop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>South Atlantic</td>\n",
       "      <td>Delaware</td>\n",
       "      <td>708.0</td>\n",
       "      <td>374.0</td>\n",
       "      <td>965479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>South Atlantic</td>\n",
       "      <td>District of Columbia</td>\n",
       "      <td>3770.0</td>\n",
       "      <td>3134.0</td>\n",
       "      <td>701547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>South Atlantic</td>\n",
       "      <td>Florida</td>\n",
       "      <td>21443.0</td>\n",
       "      <td>9587.0</td>\n",
       "      <td>21244317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>South Atlantic</td>\n",
       "      <td>Georgia</td>\n",
       "      <td>6943.0</td>\n",
       "      <td>2556.0</td>\n",
       "      <td>10511131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>South Atlantic</td>\n",
       "      <td>Maryland</td>\n",
       "      <td>4914.0</td>\n",
       "      <td>2230.0</td>\n",
       "      <td>6035802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Mid-Atlantic</td>\n",
       "      <td>New Jersey</td>\n",
       "      <td>6048.0</td>\n",
       "      <td>3350.0</td>\n",
       "      <td>8886025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Mid-Atlantic</td>\n",
       "      <td>New York</td>\n",
       "      <td>39827.0</td>\n",
       "      <td>52070.0</td>\n",
       "      <td>19530351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>South Atlantic</td>\n",
       "      <td>North Carolina</td>\n",
       "      <td>6451.0</td>\n",
       "      <td>2817.0</td>\n",
       "      <td>10381615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Mid-Atlantic</td>\n",
       "      <td>Pennsylvania</td>\n",
       "      <td>8163.0</td>\n",
       "      <td>5349.0</td>\n",
       "      <td>12800922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>South Atlantic</td>\n",
       "      <td>South Carolina</td>\n",
       "      <td>3082.0</td>\n",
       "      <td>851.0</td>\n",
       "      <td>5084156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>South Atlantic</td>\n",
       "      <td>Virginia</td>\n",
       "      <td>3928.0</td>\n",
       "      <td>2047.0</td>\n",
       "      <td>8501286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>South Atlantic</td>\n",
       "      <td>West Virginia</td>\n",
       "      <td>1021.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>1804291</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            region                 state  individuals  family_members  \\\n",
       "7   South Atlantic              Delaware        708.0           374.0   \n",
       "8   South Atlantic  District of Columbia       3770.0          3134.0   \n",
       "9   South Atlantic               Florida      21443.0          9587.0   \n",
       "10  South Atlantic               Georgia       6943.0          2556.0   \n",
       "20  South Atlantic              Maryland       4914.0          2230.0   \n",
       "30    Mid-Atlantic            New Jersey       6048.0          3350.0   \n",
       "32    Mid-Atlantic              New York      39827.0         52070.0   \n",
       "33  South Atlantic        North Carolina       6451.0          2817.0   \n",
       "38    Mid-Atlantic          Pennsylvania       8163.0          5349.0   \n",
       "40  South Atlantic        South Carolina       3082.0           851.0   \n",
       "46  South Atlantic              Virginia       3928.0          2047.0   \n",
       "48  South Atlantic         West Virginia       1021.0           222.0   \n",
       "\n",
       "    state_pop  \n",
       "7      965479  \n",
       "8      701547  \n",
       "9    21244317  \n",
       "10   10511131  \n",
       "20    6035802  \n",
       "30    8886025  \n",
       "32   19530351  \n",
       "33   10381615  \n",
       "38   12800922  \n",
       "40    5084156  \n",
       "46    8501286  \n",
       "48    1804291  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Subset for rows in South Atlantic or Mid-Atlantic regions\n",
    "homelessness[homelessness['region'].isin(['South Atlantic', 'Mid-Atlantic'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adding new columns\n",
    "You aren't stuck with just the data you are given. Instead, you can add new columns to a DataFrame. This has many names, such as transforming, mutating, and feature engineering.\n",
    "\n",
    "You can create new columns from scratch, but it is also common to derive them from other columns, for example, by adding columns together or by changing their units."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               region       state  individuals  family_members  state_pop  \\\n",
      "0  East South Central     Alabama       2570.0           864.0    4887681   \n",
      "1             Pacific      Alaska       1434.0           582.0     735139   \n",
      "2            Mountain     Arizona       7259.0          2606.0    7158024   \n",
      "3  West South Central    Arkansas       2280.0           432.0    3009733   \n",
      "4             Pacific  California     109008.0         20964.0   39461588   \n",
      "\n",
      "      total  p_individuals  \n",
      "0    3434.0       0.748398  \n",
      "1    2016.0       0.711310  \n",
      "2    9865.0       0.735834  \n",
      "3    2712.0       0.840708  \n",
      "4  129972.0       0.838704  \n"
     ]
    }
   ],
   "source": [
    "# Add total col as sum of individuals and family_members\n",
    "homelessness['total'] = homelessness['individuals'] + homelessness['family_members']\n",
    "\n",
    "# Add p_individuals col as proportion of total that are individuals\n",
    "homelessness['p_individuals'] = homelessness['individuals'] / homelessness['total']\n",
    "\n",
    "# See the result\n",
    "print(homelessness.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mean and median\n",
    "Summary statistics are exactly what they sound like - they summarize many numbers in one statistic. For example, mean, median, minimum, maximum, and standard deviation are summary statistics. Calculating summary statistics allows you to get a better sense of your data, even if there's a lot of it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 23843.95014850566\n",
      "median: 12049.064999999999\n"
     ]
    }
   ],
   "source": [
    "sales = pd.read_csv('../data/walmart.csv')\n",
    "\n",
    "# Print the mean of weekly_sales\n",
    "print(f\"mean: {sales['weekly_sales'].mean()}\")\n",
    "\n",
    "# Print the median of weekly_sales\n",
    "print(f\"median: {sales['weekly_sales'].median()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summarizing dates\n",
    "Summary statistics can also be calculated on date columns that have values with the data type datetime64. Some summary statistics — like mean — don't make a ton of sense on dates, but others are super helpful, for example, minimum and maximum, which allow you to see what time range your data covers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max: 2012-10-26\n",
      "min: 2010-02-05\n"
     ]
    }
   ],
   "source": [
    "# Print the maximum of the date column\n",
    "print(f\"max: {sales['date'].max()}\")\n",
    "\n",
    "# Print the minimum of the date column\n",
    "print(f\"min: {sales['date'].min()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Efficient summaries\n",
    "While pandas and NumPy have tons of functions, sometimes, you may need a different function to summarize your data.\n",
    "\n",
    "The .agg() method allows you to apply your own custom functions to a DataFrame, as well as apply functions to more than one column of a DataFrame at once, making your aggregations super-efficient.\n",
    "\n",
    "In the custom function for this exercise, \"IQR\" is short for inter-quartile range, which is the 75th percentile minus the 25th percentile. It's an alternative to standard deviation that is helpful if your data contains outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IQR: 16.583333333333336\n"
     ]
    }
   ],
   "source": [
    "# A custom IQR function\n",
    "def iqr(column):\n",
    "    return column.quantile(0.75) - column.quantile(0.25)\n",
    "    \n",
    "# Print IQR of the temperature_c column\n",
    "print(f\"IQR: {sales['temperature_c'].agg(iqr)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        temperature_c  fuel_price_usd_per_l  unemployment\n",
      "iqr         16.583333              0.073176         0.565\n",
      "median      16.966667              0.743381         8.099\n"
     ]
    }
   ],
   "source": [
    "# Update to print IQR of temperature_c, fuel_price_usd_per_l, & unemployment and us NumPy median\n",
    "import numpy as np\n",
    "print(sales[[\"temperature_c\", 'fuel_price_usd_per_l', 'unemployment']].agg([iqr, np.median]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cumulative statistics\n",
    "Cumulative statistics can also be helpful in tracking summary statistics over time. In this exercise, you'll calculate the cumulative sum and cumulative max of a department's weekly sales, which will allow you to identify what the total sales were so far as well as what the highest weekly sales were so far."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          date  weekly_sales  cum_weekly_sales  cum_max_sales\n",
      "0   2010-02-05      24924.50          24924.50       24924.50\n",
      "1   2010-03-05      21827.90          46752.40       24924.50\n",
      "2   2010-04-02      57258.43         104010.83       57258.43\n",
      "3   2010-05-07      17413.94         121424.77       57258.43\n",
      "4   2010-06-04      17558.09         138982.86       57258.43\n",
      "5   2010-07-02      16333.14         155316.00       57258.43\n",
      "6   2010-08-06      17508.41         172824.41       57258.43\n",
      "7   2010-09-03      16241.78         189066.19       57258.43\n",
      "8   2010-10-01      20094.19         209160.38       57258.43\n",
      "9   2010-11-05      34238.88         243399.26       57258.43\n",
      "10  2010-12-03      22517.56         265916.82       57258.43\n",
      "11  2011-01-07      15984.24         281901.06       57258.43\n"
     ]
    }
   ],
   "source": [
    "# Create a sales data for department 1 of store 1 and add copy method to explicitly copy the data\n",
    "sales_1_1 = sales[(sales['department'] == 1) & (sales['store'] == 1)].copy()\n",
    "\n",
    "# Get the cumulative sum of weekly_sales, add as cum_weekly_sales col\n",
    "sales_1_1['cum_weekly_sales'] = sales_1_1['weekly_sales'].cumsum()\n",
    "\n",
    "# Get the cumulative max of weekly_sales, add as cum_max_sales col\n",
    "sales_1_1['cum_max_sales'] = sales_1_1['weekly_sales'].cummax()\n",
    "\n",
    "# See the columns you calculated\n",
    "print(sales_1_1[[\"date\", \"weekly_sales\", \"cum_weekly_sales\", \"cum_max_sales\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dropping duplicates\n",
    "Removing duplicates is an essential skill to get accurate counts because often, you don't want to count the same thing multiple times. In this exercise, you'll create some new DataFrames using unique values from sales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      store type  department        date  weekly_sales  is_holiday  \\\n",
      "0         1    A           1  2010-02-05      24924.50       False   \n",
      "901       2    A           1  2010-02-05      35034.06       False   \n",
      "1798      4    A           1  2010-02-05      38724.42       False   \n",
      "2699      6    A           1  2010-02-05      25619.00       False   \n",
      "3593     10    B           1  2010-02-05      40212.84       False   \n",
      "4495     13    A           1  2010-02-05      46761.90       False   \n",
      "5408     14    A           1  2010-02-05      32842.31       False   \n",
      "6293     19    A           1  2010-02-05      21500.58       False   \n",
      "7199     20    A           1  2010-02-05      46021.21       False   \n",
      "8109     27    A           1  2010-02-05      32313.79       False   \n",
      "9009     31    A           1  2010-02-05      18187.71       False   \n",
      "9899     39    A           1  2010-02-05      21244.50       False   \n",
      "\n",
      "      temperature_c  fuel_price_usd_per_l  unemployment  \n",
      "0          5.727778              0.679451         8.106  \n",
      "901        4.550000              0.679451         8.324  \n",
      "1798       6.533333              0.686319         8.623  \n",
      "2699       4.683333              0.679451         7.259  \n",
      "3593      12.411111              0.782478         9.765  \n",
      "4495      -0.261111              0.704283         8.316  \n",
      "5408      -2.605556              0.735455         8.992  \n",
      "6293      -6.133333              0.780365         8.350  \n",
      "7199      -3.377778              0.735455         8.187  \n",
      "8109      -2.672222              0.780365         8.237  \n",
      "9009       3.916667              0.679451         8.324  \n",
      "9899       6.833333              0.679451         8.554  \n"
     ]
    }
   ],
   "source": [
    "# Drop duplicate store/type combinations\n",
    "store_types = sales.drop_duplicates(subset=['store', 'type'])\n",
    "print(store_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       store type  department        date  weekly_sales  is_holiday  \\\n",
      "0          1    A           1  2010-02-05      24924.50       False   \n",
      "12         1    A           2  2010-02-05      50605.27       False   \n",
      "24         1    A           3  2010-02-05      13740.12       False   \n",
      "36         1    A           4  2010-02-05      39954.04       False   \n",
      "48         1    A           5  2010-02-05      32229.38       False   \n",
      "...      ...  ...         ...         ...           ...         ...   \n",
      "10715     39    A          95  2010-02-05      88385.24       False   \n",
      "10727     39    A          96  2010-02-05      21450.05       False   \n",
      "10739     39    A          97  2010-02-05      21162.05       False   \n",
      "10751     39    A          98  2010-02-05       9023.09       False   \n",
      "10763     39    A          99  2010-03-05          0.01       False   \n",
      "\n",
      "       temperature_c  fuel_price_usd_per_l  unemployment  \n",
      "0           5.727778              0.679451         8.106  \n",
      "12          5.727778              0.679451         8.106  \n",
      "24          5.727778              0.679451         8.106  \n",
      "36          5.727778              0.679451         8.106  \n",
      "48          5.727778              0.679451         8.106  \n",
      "...              ...                   ...           ...  \n",
      "10715       6.833333              0.679451         8.554  \n",
      "10727       6.833333              0.679451         8.554  \n",
      "10739       6.833333              0.679451         8.554  \n",
      "10751       6.833333              0.679451         8.554  \n",
      "10763      10.516667              0.693452         8.554  \n",
      "\n",
      "[929 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "# Drop duplicate store/department combinations\n",
    "store_depts = sales.drop_duplicates(subset=['store', 'department'])\n",
    "print(store_depts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "498     2010-09-10\n",
      "691     2011-11-25\n",
      "2315    2010-02-12\n",
      "6735    2012-09-07\n",
      "6810    2010-12-31\n",
      "6815    2012-02-10\n",
      "6820    2011-09-09\n",
      "Name: date, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Subset the rows where is_holiday is True and drop duplicate dates\n",
    "holiday_dates = sales[sales['is_holiday']].drop_duplicates(subset='date')\n",
    "\n",
    "# Print date col of holiday_dates\n",
    "print(holiday_dates['date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Counting categorical variables\n",
    "Counting is a great way to get an overview of your data and to spot curiosities that you might not notice otherwise. In this exercise, you'll count the number of each type of store and the number of each department number using the DataFrames you created in the previous exercise:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A    11\n",
      "B     1\n",
      "Name: type, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Count the number of stores of each type\n",
    "store_counts = store_types['type'].value_counts()\n",
    "print(store_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A    0.916667\n",
      "B    0.083333\n",
      "Name: type, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Get the proportion of stores of each type\n",
    "store_props = store_types['type'].value_counts(normalize=True)\n",
    "print(store_props)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1     12\n",
      "55    12\n",
      "72    12\n",
      "71    12\n",
      "67    12\n",
      "      ..\n",
      "37    10\n",
      "48     8\n",
      "50     6\n",
      "39     4\n",
      "43     2\n",
      "Name: department, Length: 80, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Count the number of each department number and sort\n",
    "dept_counts_sorted = store_depts['department'].value_counts(sort=True)\n",
    "print(dept_counts_sorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1     0.012917\n",
      "55    0.012917\n",
      "72    0.012917\n",
      "71    0.012917\n",
      "67    0.012917\n",
      "        ...   \n",
      "37    0.010764\n",
      "48    0.008611\n",
      "50    0.006459\n",
      "39    0.004306\n",
      "43    0.002153\n",
      "Name: department, Length: 80, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Get the proportion of departments of each number and sort\n",
    "dept_props_sorted = store_depts['department'].value_counts(sort=True, normalize=True)\n",
    "print(dept_props_sorted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grouped summary statistics\n",
    "While .groupby() is useful, you can calculate grouped summary statistics without it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9097747 0.0902253 0.       ]\n"
     ]
    }
   ],
   "source": [
    "# Calc total weekly sales\n",
    "sales_all = sales[\"weekly_sales\"].sum()\n",
    "\n",
    "# Subset for type A stores, calc total weekly sales\n",
    "sales_A = sales[sales['type'] == 'A']['weekly_sales'].sum()\n",
    "\n",
    "# Subset for type B stores, calc total weekly sales\n",
    "sales_B = sales[sales['type'] == 'B']['weekly_sales'].sum()\n",
    "\n",
    "# Subset for type C stores, calc total weekly sales\n",
    "sales_C = sales[sales['type'] == 'C']['weekly_sales'].sum()\n",
    "\n",
    "# Get proportion for each type\n",
    "sales_propn_by_type = [sales_A, sales_B, sales_C] / sales_all\n",
    "\n",
    "print(sales_propn_by_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The .groupby() method makes life much easier. In this exercise, you'll perform the same calculations as last time, except you'll use the .groupby() method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type\n",
      "A    0.909775\n",
      "B    0.090225\n",
      "Name: weekly_sales, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "sales_by_type = sales.groupby(\"type\")[\"weekly_sales\"].sum() / sales['weekly_sales'].sum()\n",
    "print(sales_by_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type  is_holiday\n",
      "A     False         2.336927e+08\n",
      "      True          2.360181e+04\n",
      "B     False         2.317678e+07\n",
      "      True          1.621410e+03\n",
      "Name: weekly_sales, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Group by type and is_holiday; calc total weekly sales\n",
    "sales_by_type_is_holiday = sales.groupby(['type', 'is_holiday'])['weekly_sales'].sum()\n",
    "print(sales_by_type_is_holiday)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multiple grouped summaries\n",
    "Earlier in this chapter, you saw that the .agg() method is useful to compute multiple statistics on multiple variables. It also works with grouped data. NumPy, which is imported as np, has many different summary statistics functions, including: np.min, np.max, np.mean, and np.median."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        amin       amax          mean    median\n",
      "type                                           \n",
      "A    -1098.0  293966.05  23674.667242  11943.92\n",
      "B     -798.0  232558.51  25696.678370  13336.08\n"
     ]
    }
   ],
   "source": [
    "# For each store type, aggregate weekly_sales: get min, max, mean, and median\n",
    "sales_stats = sales.groupby('type')['weekly_sales'].agg([np.min, np.max, np.mean, np.median])\n",
    "\n",
    "# Print sales_stats\n",
    "print(sales_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     unemployment                         fuel_price_usd_per_l            \\\n",
      "             amin   amax      mean median                 amin      amax   \n",
      "type                                                                       \n",
      "A           3.879  8.992  7.972611  8.067             0.664129  1.107410   \n",
      "B           7.170  9.765  9.279323  9.199             0.760023  1.107674   \n",
      "\n",
      "                          \n",
      "          mean    median  \n",
      "type                      \n",
      "A     0.744619  0.735455  \n",
      "B     0.805858  0.803348  \n"
     ]
    }
   ],
   "source": [
    "# For each store type, aggregate unemployment and fuel_price_usd_per_l: get min, max, mean, and median\n",
    "unemp_fuel_stats = sales.groupby('type')[['unemployment', 'fuel_price_usd_per_l']].agg([np.min, np.max, np.mean, np.median])\n",
    "\n",
    "# Print unemp_fuel_stats\n",
    "print(unemp_fuel_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pivoting on one variable\n",
    "Pivot tables are the standard way of aggregating data in spreadsheets.\n",
    "\n",
    "In pandas, pivot tables are essentially another way of performing grouped calculations. That is, the .pivot_table() method is an alternative to .groupby().\n",
    "\n",
    "In this exercise, you'll perform calculations using .pivot_table() to replicate the calculations you performed in the last lesson using .groupby()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      weekly_sales\n",
      "type              \n",
      "A     23674.667242\n",
      "B     25696.678370\n"
     ]
    }
   ],
   "source": [
    "# Pivot for mean weekly_sales for each store type\n",
    "mean_sales_by_type = sales.pivot_table(values='weekly_sales', index='type')\n",
    "\n",
    "# Print mean_sales_by_type\n",
    "print(mean_sales_by_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              mean       median\n",
      "      weekly_sales weekly_sales\n",
      "type                           \n",
      "A     23674.667242     11943.92\n",
      "B     25696.678370     13336.08\n"
     ]
    }
   ],
   "source": [
    "# Pivot for mean and median weekly_sales for each store type\n",
    "mean_med_sales_by_type = sales.pivot_table(values='weekly_sales', index='type', aggfunc=[np.mean, np.median])\n",
    "\n",
    "# Print mean_med_sales_by_type\n",
    "print(mean_med_sales_by_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **fill_value** replaces missing values with a real value (known as imputation). What to replace missing values with is a topic big enough to have its own course (Dealing with Missing Data in Python), but the simplest thing to do is to substitute a dummy value.\n",
    "\n",
    "- **margins** is a shortcut for when you pivoted by two variables, but also wanted to pivot by each of those variables separately: it gives the row and column totals of the pivot table contents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type                   A              B\n",
      "department                             \n",
      "1           30961.725379   44050.626667\n",
      "2           67600.158788  112958.526667\n",
      "3           17160.002955   30580.655000\n",
      "4           44285.399091   51219.654167\n",
      "5           34821.011364   63236.875000\n"
     ]
    }
   ],
   "source": [
    "# Pivot for mean weekly_sales by store type and department \n",
    "mean_sales_by_type_department = sales.pivot_table(values='weekly_sales', index='department', columns='type', fill_value=0)\n",
    "\n",
    "# Print mean_sales_by_type_department\n",
    "print(mean_sales_by_type_department.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setting and removing indexes\n",
    "pandas allows you to designate columns as an index. This enables cleaner code when taking subsets (as well as providing more efficient lookup under some circumstances)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before:\n",
      "         date     city        country  avg_temp_c\n",
      "0  2000-01-01  Abidjan  Côte D'Ivoire      27.293\n",
      "1  2000-02-01  Abidjan  Côte D'Ivoire      27.685\n",
      "2  2000-03-01  Abidjan  Côte D'Ivoire      29.061\n",
      "3  2000-04-01  Abidjan  Côte D'Ivoire      28.162\n",
      "4  2000-05-01  Abidjan  Côte D'Ivoire      27.547\n",
      "\n",
      "After:\n",
      "               date        country  avg_temp_c\n",
      "city                                          \n",
      "Abidjan  2000-01-01  Côte D'Ivoire      27.293\n",
      "Abidjan  2000-02-01  Côte D'Ivoire      27.685\n",
      "Abidjan  2000-03-01  Côte D'Ivoire      29.061\n",
      "Abidjan  2000-04-01  Côte D'Ivoire      28.162\n",
      "Abidjan  2000-05-01  Côte D'Ivoire      27.547\n"
     ]
    }
   ],
   "source": [
    "temperatures = pd.read_csv('../data/temperatures.csv')\n",
    "\n",
    "# Look at temperatures\n",
    "print(f'Before:\\n{temperatures.head()}\\n')\n",
    "\n",
    "# Set the index of temperatures to city\n",
    "temperatures_ind = temperatures.set_index('city')\n",
    "\n",
    "# Look at temperatures_ind\n",
    "print(f'After:\\n{temperatures_ind.head()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      city        date        country  avg_temp_c\n",
      "0  Abidjan  2000-01-01  Côte D'Ivoire      27.293\n",
      "1  Abidjan  2000-02-01  Côte D'Ivoire      27.685\n",
      "2  Abidjan  2000-03-01  Côte D'Ivoire      29.061\n",
      "3  Abidjan  2000-04-01  Côte D'Ivoire      28.162\n",
      "4  Abidjan  2000-05-01  Côte D'Ivoire      27.547\n"
     ]
    }
   ],
   "source": [
    "# Reset the temperatures_ind index, keeping its contents\n",
    "print(temperatures_ind.reset_index().head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         date        country  avg_temp_c\n",
      "0  2000-01-01  Côte D'Ivoire      27.293\n",
      "1  2000-02-01  Côte D'Ivoire      27.685\n",
      "2  2000-03-01  Côte D'Ivoire      29.061\n",
      "3  2000-04-01  Côte D'Ivoire      28.162\n",
      "4  2000-05-01  Côte D'Ivoire      27.547\n"
     ]
    }
   ],
   "source": [
    "# Reset the temperatures_ind index, dropping its contents\n",
    "print(temperatures_ind.reset_index(drop=True).head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data-analytics",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
